---
title: Japanese dialects and ASR
---

[←](/)

# 5/27

Some Japanese dialects are quite divergent relative to the standard (標準語), and some are divergent enough (Kyushu dialects) that they may be more corretly considered low-resource languages. 
Many of these dialects are spoken by aging populations, where language technology (like ASR and TTS) may be quite useful, enabling access to information in their native dialect. 
How well do SOTA ASR models handle Japanese regional dialects?
There is a nice resource in [CPJD (Crowdsourced Parallel Speech Corpus of Japanese Dialects)](https://sites.google.com/site/shinnosuketakamichi/research-topics/cpjd_corpus?authuser=0), a parallel speech-text dataset covering 20 regional dialects. We'll see how the best models do.

## The Dialect Data

The data consists of 250 utterances by 21 speakers, each asked to translate the same phrase to their native dialect. The variety is quite interesting, just taking the first utterance in a Miyazaki-Morokata dialect ("it seems like they’re trying to handle everything in their life using just a smartphone as much as possible"):

でくいごっ，スマートフォンひとっで，身の回りんこっ，根っかい片そちしちょっごたっ。

and comparing it to Saitama, which seems similar to 標準語:

できるだけ，スマートフォンひとつで，身の回りのこと全て片付けようとしているようだ。

As an N3~N2 Japanese learner, I can mostly make sense of the Saitama-ben transcription, but the Miyazaki-Morokata dialect seems to be mutually untelligible with standard Japanese (according to the [wikipedia page](https://en.wikipedia.org/wiki/Kagoshima_dialect), also with other Kyushu dialects).

## The Evals

To measure performance, we'll look at Character Error Rate (CER), (percentage of incorrect characters predicted compared to GT) which seem to be around 5–10% on cleared datasets based on the evals in [@kotoba-tech/kotoba-whisper](https://github.com/kotoba-tech/kotoba-whisper).